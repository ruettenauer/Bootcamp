{
  "hash": "3a61591fcc78aaf3e931113d39d53837",
  "result": {
    "markdown": "---\ntitle: \"Quantitative Methods Bootcamp\"\nauthor: \"Rocio Mendez Pineda & Tobias Rüttenauer\"\nformat: revealjs\ndate: \"2023-09-28\"\nexecute:\n  freeze: auto  # re-render only when source changes\n---\n\n\n## Before We Start\n\n* Go to: [https://github.com/ruettenauer/Bootcamp](https://github.com/ruettenauer/Bootcamp)\n\n* Download: \n  + The slides for this bootcamp \n  + The dataset we will use (“WDI_Data.dta”)\n\n* Make sure to save the dataset in an easy-to-access folder\n  + A place you can also access from elsewhere (e.g., N-drive) \n  \n  \n## Objectives of This Bootcamp\n\n#### Overarching goal\n\nBe on common starting point + ready to take on the quantitative MSc modules\n\n::: {.incremental}\n* Refresh key statistical concepts \n  - E.g., sampling distributions, hypothesis testing \n* Obtain basic familiarity with R & Stata \n:::\n\n\n## Statistical Inference\n  \nStatistical inference is used to learn from incomplete data\n\n. . .\n\nWe wish to learn some characteristics of a population (e.g., the mean and standard deviation of the heights of all women in the UK), which we must estimate from a sample or subset of that population\n\n. . .\n\n### Two types of inference:\n\n::: {.incremental}\n1) __Descriptive inference__: What is going on, or what exists? \n2) __Causal inference__: Why is something going on, why does it exist? \n:::\n\n\n## Example data {.scrollable}\n\nThe code below loads the WDI packages and searches for an indicator on CO2 per capita.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load package\nlibrary(WDI)\n\n# Search GDP per capita\nWDIsearch(\"CO2.*capita\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          indicator\n6032 EN.ATM.CO2E.PC\n6048 EN.ATM.METH.PC\n6059 EN.ATM.NOXE.PC\n                                                                   name\n6032                             CO2 emissions (metric tons per capita)\n6048                Methane emissions (kt of CO2 equivalent per capita)\n6059 Nitrous oxide emissions (metric tons of CO2 equivalent per capita)\n```\n:::\n:::\n\n\nThe code below uses the WDI API to retrieve the data and creates a dataframe of three indicators.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define countries, indicators form above, and time period\nwd.df <- WDI(country = \"all\", \n             indicator = c('population' = \"SP.POP.TOTL\", \n                           'gdp_pc' = \"NY.GDP.PCAP.KD\", \n                           'co2_pc' = \"EN.ATM.CO2E.PC\"),\n             extra = TRUE,\n             start = 2019, end = 2019)\n\n# Drop all country aggregrates\nwd.df <- wd.df[which(wd.df$region != \"Aggregates\"), ]\n\n# Save data\nsave(wd.df, file = \"WDI_short.RData\")\n```\n:::\n\n\n\n## Descriptive Inference\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\nlibrary(ggplot2)\npl <- ggplot(wd.df, aes(x = gdp_pc, y = co2_pc, size = population, color = region)) +\n  geom_point(alpha = 0.5) + \n  theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) +\n  labs(y = \"CO2 emissions per capita\", x = \"GDP per capita\")\n\npl\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/wdi_plot1-1.png){width=960}\n:::\n:::\n\n\n__Descriptive__: What are the average CO2 emissions of all highly populated countries countries?\n\n\n## Causal Inference\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\npl2 <- ggplot(wd.df, aes(x = gdp_pc, y = co2_pc, size = population, color = region)) +\n  geom_smooth(aes(group = 1), show.legend = \"none\") + geom_point(alpha = 0.5) + \n  theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) +\n  labs(y = \"CO2 emissions per capita\", x = \"GDP per capita\")\n\npl2\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/wdi_plot2-1.png){width=960}\n:::\n:::\n\n\n__Causal__: How does GDP influence the amount of CO2 emissions?\n\n\n## Variables and Observations  {.smaller}\n\nA [variable]{style=\"color: red;\"} is anything that can vary across units of analysis: it is a characteristic that can have multiple values\n\n* E.g., sex, age, diameter, financial revenue, temperature\n\n. . .\n\nA [unit of analysis]{style=\"color: blue;\"} is the major entity that you analyse\n\n*\tE.g., individuals, objects, schools, countries\n\n. . .\n\nAn [observation]{style=\"color: purple;\"} is the value of a particular variable for a particular unit (sometimes a unit is in its entirety referred to as observation)\n\n*\tE.g., the [individual]{style=\"color: blue;\"} King Charles III is [73 years]{style=\"color: purple;\"} of [age]{style=\"color: red;\"}\n\n\n## Different Types of Variables {.smaller}\n\n#### Continuous / interval-ratio variables: \n\nThey have an ordering, they can take on infinitely many values, and you can do calculations with them\n\n::: {.fragment .fade-in}\n* E.g., income, age, weight, minutes\n:::\n\n::: {.fragment .fade-in}\n#### Categorical variables: \n\nEach observation belongs to one out of a fixed number of categories \n\n* Ordinal variables: there is a natural ordering of the categories\n* Nominal variables: there is no natural ordering of the categories\n\n::: {.fragment .fade-in}\n  - E.g., education level, Likert scales, gender, vote choice\n:::\n:::\n\n# Describing variables\n\n## Decribing variables\n\nDescribing data is necessary because there is usually too much of it, so it does not make any sense to look at every data point\n\nWe thus have to look for ways to summarize central tendencies, variation, and relationships that exist in the data\n\nThere are many different ways to do this\n\n::: {.incremental}\n1) Visual depictions\n2) Numerical descriptions\n  - E.g. mean, mode, median, standard deviation\n:::\n\n\n## Distribution\n\nVariables can be characterized by their __frequency distribution__: \n\nThe distribution of the (relative) frequencies of their values  \n\n  - E.g., we can graph the world income distribution:\n\n## {auto-animate=true}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\np <- ggplot(wd.df, aes(x = gdp_pc)) + geom_density() + \n  labs(y = \"Density\", x = \"GDP per capita\") + theme_bw()\np\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/distributions1-1.png){width=960}\n:::\n:::\n\n\n## Distributions: Examples\n\n* Normal distribution\n\n* Chi-squared distribution\n\n## {auto-animate=true}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\n# Seed for random number\nset.seed(12345)\n\n# Normal distribution\nd1 <- data.frame(x = rnorm(10000, 0, 1), dist = \"mean = 0, sd = 1\")\nd2 <- data.frame(x = rnorm(10000, 1, 1), dist = \"mean = 1, sd = 1\")\nd3 <- data.frame(x = rnorm(10000, 0, 2), dist = \"mean = 0, sd = 2\")\n\np <- ggplot(rbind(d1, d2, d3), aes(x = x)) + \n  geom_density(aes(color = dist, linetype = dist), size = 1.5) + \n  labs(y = \"Density\", x = \"Variable x\") + theme_bw() +\n  ggtitle(\"Normal distribution\")\np\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/distributions2-1.png){width=960}\n:::\n:::\n\n\n## {auto-animate=true}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\n# Chi Squared distribution\nd2 <- data.frame(x = rchisq(10000, 2), dist = \"df = 2\")\nd3 <- data.frame(x = rchisq(10000, 4), dist = \"df = 4\")\nd4 <- data.frame(x = rchisq(10000, 8), dist = \"df = 8\")\n\np <- ggplot(rbind(d2, d3, d4), aes(x = x)) + \n  geom_density(aes(color = dist, linetype = dist), size = 1.5) + \n  labs(y = \"Density\", x = \"Variable x\") + theme_bw() +\n  ggtitle(\"Chi-squared distribution\")\np\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/distributions3-1.png){width=960}\n:::\n:::\n\n\n## {auto-animate=true}\n\n#### Distributions can take on many different shapes\n\n![](figs/Picture1.png)\n\n\n## Measures of Central Tendency {.smaller}\n\n__Mean__: conventional average calculated by adding all values for all units and dividing by the number of units\n\n$$\\overline{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}=\\frac{1}{n}\\left(x_{1}+\\cdots+x_{n}\\right), \\mathrm{with~units~}i = (1, 2, \\dots, n)$$\n\n* May give a distorted impression if there are outliers\n\n. . .\n\n__Median__: value that falls in the middle if we order all units by their value on the variable\n\n. . .\n\n__Mode__: most frequently occurring value across all units\n\n\n## Measures of Dispersion  {.smaller}\n\n__Variance__: average of the squared differences between each observed value on a variable and its mean \n$$\n\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2\n$$\n\n* Why the square? To treat + and – differences alike\n\n. . .\n\n__Standard deviation__: average departure of the observed values on a variable from its mean\n\n$$\n\\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2}\n$$\n\n* It is the square root of the variance; it “reverts” the square-taking in the variance calculation, to bring the statistic back to the original scale of the variable\n\n\n## Notation {.smaller}\n\nTypically, we use Roman letters for sample statistics and Greek letters for population statistics:\n\n* Sample mean $= \\bar{x}$ population mean $= \\mu$\n* Sample variance $= s^2$, population variance $= \\sigma^2$\n* Sample standard error $= s$, population standard deviation $= \\sigma$ \n\nRecall: the sample is what we observe, the population is what we want to make inferences about\n\n\n\n# Decribing relationships\n\n## Decribing relationships\n\nOften, we are not just interested in the distribution of a single variable. ^[Yeah, you could have spend the last 30 minutes on instagram!]\n\n. . .\n\nInstead, we are interested in __relationships__ between several variables. If there is a relationship between variable, knowing one variable can tell you something about the other variable.\n\n::: {.incremental}\n* Age and height\n* GDP and CO2 emissions\n* Education and income\n:::\n\n## Hypothesis testing \n\nA hypothesis is a theory-based statement about a relationship that we expect to observe\n\n* E.g., girls achieve higher scores than boys on reading tests \n\n. . .\n\nFor every hypothesis there is a corresponding null hypothesis about what we would expect if our theory is incorrect\n\n. . .\n\n* E.g., there is no association between Y and X in the population\n* In our example: girls are not better readers than boys \n\n\n## Covariance {.smaller}\n\n__Covariance__ refers to the idea that the pattern of variation for one variable corresponds to the pattern of variation for another variable: the two variables “vary together” \n\nStatistically speaking, covariance is the multiplication of the deviations from the mean for the first variables and the deviations from the mean for the second variable:\n\n$$cov_{x,y}=\\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})$$\n\n::: {.incremental}\n* The covariance tells us the direction of an association: + or – \n* It does not tell us about the strength of the association (reference to underlying distributions of variables is missing)\n:::\n\n\n\n## Pearson’s Correlation {.smaller}\n\nFor continuous data, we can calculate Pearson's correlation ($\\rho$)\n\n* $\\rho$ measures strength & direction of association for linear trends\n* $\\rho$ rescales the covariance to the underlying distributions of the variables involved:\n\n$$ \\rho = \\frac{cov_{x,y}}{\\sigma_X \\sigma_Y} = \n\\frac{\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}\n{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\bar{y})^2}}$$\n\n. . .\n\nDividing the covariance by the product of the standard deviations normalizes the covariance to a range from -1 to +1\n\n::: {.incremental}\n* -1 = perfectly negative correlation (all points on decreasing line)\n* +1 = perfectly positive correlation (all points on increasing line)\n* 0 = no correlation (random cloud of points)\n* Correlation is weaker closer to 0 and stronger closer to +/-1\n:::\n\n\n## An Example\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npl\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n\n## An Example I\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# use log transformed variables\nwd.df$ln_gdp_pc <- log(wd.df$gdp_pc)\nwd.df$ln_co2_pc <- log(wd.df$co2_pc)\n\n# calculate covariance\ncov <- cov(wd.df$ln_gdp_pc, wd.df$ln_co2_pc, use = \"complete.obs\")\n\n# sd\nsd_gdp <- sd(wd.df$ln_gdp_pc, na.rm = TRUE)\nsd_co2 <- sd(wd.df$ln_co2_pc, na.rm = TRUE)\n\n# correlation\ncor <- cor(wd.df$ln_gdp_pc, wd.df$ln_co2_pc, use = \"complete.obs\")\n\n# Plot with linear line\npl3 <- ggplot(wd.df, aes(x = gdp_pc, y = co2_pc, size = population, color = region)) +\n  geom_smooth(aes(group = 1), method = 'lm', show.legend = \"none\") + \n  geom_point(alpha = 0.5) + \n  theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) +\n  labs(y = \"CO2 emissions per capita\", x = \"GDP per capita\") +\n  ggtitle(paste(\"Pearsons correlation = \", round(cor, 3)))\n\npl3\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n## An Example II\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# use log transformed variables\nwd.df$ln_population <- log(wd.df$population)\nwd.df$ln_co2_pc <- log(wd.df$co2_pc)\n\n# calculate covariance\ncov <- cov(wd.df$ln_population, wd.df$ln_co2_pc, use = \"complete.obs\")\n\n# sd\nsd_gdp <- sd(wd.df$ln_population, na.rm = TRUE)\nsd_co2 <- sd(wd.df$ln_co2_pc, na.rm = TRUE)\n\n# correlation\ncor <- cor(wd.df$ln_population, wd.df$ln_co2_pc, use = \"complete.obs\")\n\n# Plot with linear line\npl3 <- ggplot(wd.df, aes(x = population, y = co2_pc, size = population, color = region)) +\n  geom_smooth(aes(group = 1), method = 'lm', show.legend = \"none\") + \n  geom_point(alpha = 0.5) + \n  theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) +\n  labs(y = \"CO2 emissions per capita\", x = \"Population\") +\n  ggtitle(paste(\"Pearsons correlation = \", round(cor, 3)))\n\npl3\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n# Statistical Software\n\n## Statistical software\n\n__Stata__ & __R__ are powerful software packages that allows you to do: \n\n* Data management and manipulation\n* Data visualization \n* Statistical analysis\n\n. . .\n\n* (Writing papers and presentations)\n\n. . .\n\nWriting Stata syntax files and R script facilitates __reproducibility__\n\n\n## Stata’s Interface: Variables Window {.smaller}\n\nThe variables window displays all variables in your dataset \n\n![](figs/Stata1.png)\n\n* Single click on variable names to see details in properties window\n* Double click to make variables appear in command window\n\n\n## Stata’s Interface: Properties Window {.smaller}\n\nThe variables window displays all variables in your dataset \n\n![](figs/Stata2.png)\n\nThe properties window displays details about selected variables as well as the entire dataset (e.g., number of observations, sort order)\n\n\n## Stata’s Interface: Command Window {.smaller}\n\n![](figs/Stata3.png)\n\nThe command window is for entering and executing commands\n\n* But it is better to use do-files (same applies to drop-down menus)\n\n\n## Stata’s Interface: Results Window  {.smaller}\n\n![](figs/Stata4.png)\n\nThe results window displays all output of your commands\n\n\n## Stata’s Interface: Command History and Current Working Directory {.smaller}\n\n![](figs/Stata5.png)\n\nThe command history window lists previously run commands \n\n* At the bottom you can see the current working directory: the folder where any files will be loaded from and saved to\n\n\n## Stata’s Interface: Opening a Do File {.smaller}\n\n![](figs/Stata6.png)\n\nDo files are text files where you can store commands for reuse\n\n* Huge payoffs for reproducibility, debugging, adapting commands\n\n\n## Running Commands from a Do File {.smaller}\n\n![](figs/Stata7.png)\n\nAfter entering a command, you select it, and then click the “execute” button or press “Ctrl+D”\n\n\n## Do File Dos and Don’ts {.smaller}\n\n![](figs/Stata8.png)\n\n1. Use annotations to facilitate replicability (incl. for future self!):\n\t* Use * for single-line comments and /* */ for multiple lines \n\n## {auto-animate=true .smaller}\n\t\n![](figs/Stata9.png)\t\n\n2. Break down code into clearly labelled sections / subsections\n3. Use tab indentations to making things easy to read\n\n## {auto-animate=true .smaller}\n\n![](figs/Stata10.png)\t\n\n4. Don’t put too much information on a single line\n\n* Use /// to continue your command on the next line and \n* write “top-to-bottom” instead of “left-to-right” \n\n\n## R & R Studio Interface\n\n![](figs/R1.png)\t\n\n\n# Structure of Commands in Stata\n\n## General Stata Command Syntax\n\n![](figs/Stata11.png)\n\nStata commands mirror everyday commands in their structure:\n\n::: {.incremental}\n* They often start with a verb: “Bring me…” \n* They then list an object: “… a pint of milk…”\n* They may add a condition: “… if it is still before noon…” \n* They may specify further details after the comma: “, quickly please” or “, I want semi-skimmed”\n:::\n\n## {auto-animate=true}\n\n![](figs/Stata11.png)\n\nIn nearly all cases, Stata syntax consists of four parts: \n\n::: {.incremental}\n* __Command__: What action do you want to see performed? \n* __Names of variables__, files, objects: On what objects is the command to be performed (“varlist”)\n* __Qualifier(s) on observations__: Which observations are to be taken into account (and how)? (“if”, “in”, “weight”)\n* __Options__: What special things should be done in the execution?\n:::\n\n\n## \"help [command]\" is your friend\n\n![](figs/Stata12.png)\n\n```{.stata}\nhelp summarize\n```\n\n\n# Structure of Commands in R\n\n\n## General R Workflow\n\n\n```{.r code-line-numbers=\"1\"}\nobject_name <- value\n\n# Example\na <- 3\nb <- 4\nc <- a + b\nc\n```\n\n* Assign a value to an object\n\n## General R Workflow\n\n```{.r code-line-numbers=\"4,5\"}\nobject_name <- value\n\n# Example\na <- 3\nb <- 4\nc <- a + b\nc\n```\n\n* Define the objects a and b\n\n## General R Workflow\n\n```{.r code-line-numbers=\"6\"}\nobject_name <- value\n\n# Example\na <- 3\nb <- 4\nc <- a + b\nc\n```\n\n* Perform an operations with them\n\n\n::: {.cell}\n\n:::\n\n\n\n## General R Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"7\"}\nobject_name <- value\n\n# Example\na <- 3\nb <- 4\nc <- a + b\nc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7\n```\n:::\n:::\n\n\n* Return the results\n\n\n## General R Syntax\n\n```{.r}\nfunction_name(arg1 = val1[which()], arg2 = val2[which()], option1 = val3, ...)\n```\n\n::: {.incremental}\n* __function_name__: What action do you want to see performed? \n* __args__, files, objects: On what objects is the command to be performed \n* __Qualifier(s) on observations__: Which observations are to be taken into account (and how)? (“which”)\n* __options__: What special things should be done in the execution?\n:::\n\n\n## General R Syntax\n\nProduce a sequence between 0 and 10 with 20 values\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- seq(0, 10, length.out = 20)\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  0.0000000  0.5263158  1.0526316  1.5789474  2.1052632  2.6315789\n [7]  3.1578947  3.6842105  4.2105263  4.7368421  5.2631579  5.7894737\n[13]  6.3157895  6.8421053  7.3684211  7.8947368  8.4210526  8.9473684\n[19]  9.4736842 10.0000000\n```\n:::\n:::\n\n\nCalculate the mean\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\nCalculate the mean of all values above 5\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(y[which(y >= 5)])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7.631579\n```\n:::\n:::\n\n\n\n\n## \"?[command]\" is your friend\n\n![](figs/R2.png)\n\n```{.r}\n?seq\n```\n",
    "supporting": [
      "Bootcamp_slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}