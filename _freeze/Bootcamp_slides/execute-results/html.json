{
  "hash": "cd998cbd8f437529e04786910ac84d3b",
  "result": {
    "markdown": "---\ntitle: \"Quantitative Methods Bootcamp\"\nauthor: \"Rocio Mendez Pineda & Tobias Rüttenauer\"\nformat: revealjs\ndate: \"2023-09-27\"\nexecute:\n  freeze: auto  # re-render only when source changes\n---\n\n\n## Before We Start\n\n* Go to: [https://github.com/ruettenauer/Bootcamp](https://github.com/ruettenauer/Bootcamp)\n\n* Download: \n  + The slides for this bootcamp \n  + The dataset we will use (“WDI_Data.dta”)\n\n* Make sure to save the dataset in an easy-to-access folder\n  + A place you can also access from elsewhere (e.g., N-drive) \n  \n  \n## Objectives of This Bootcamp\n\n#### Overarching goal\n\nBe on common starting point + ready to take on the quantitative MSc modules\n\n::: {.incremental}\n* Refresh key statistical concepts \n  - E.g., sampling distributions, hypothesis testing \n* Obtain basic familiarity with R & Stata \n:::\n\n\n## Statistical Inference\n  \nStatistical inference is used to learn from incomplete data\n\n. . .\n\nWe wish to learn some characteristics of a population (e.g., the mean and standard deviation of the heights of all women in the UK), which we must estimate from a sample or subset of that population\n\n. . .\n\n### Two types of inference:\n\n::: {.incremental}\n1) __Descriptive inference__: What is going on, or what exists? \n2) __Causal inference__: Why is something going on, why does it exist? Does X cause Y?\n:::\n\n\n## Example data {.scrollable .smaller}\n\nThe code below loads the WDI packages and searches for an indicator on CO2 per capita. It uses the statistics software R (more later).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load package\nlibrary(WDI)\n\n# Search GDP per capita (log-transformed)\nWDIsearch(\"CO2.*capita\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          indicator\n6032 EN.ATM.CO2E.PC\n6048 EN.ATM.METH.PC\n6059 EN.ATM.NOXE.PC\n                                                                   name\n6032                             CO2 emissions (metric tons per capita)\n6048                Methane emissions (kt of CO2 equivalent per capita)\n6059 Nitrous oxide emissions (metric tons of CO2 equivalent per capita)\n```\n:::\n:::\n\n\nThe code below uses the WDI API to retrieve the data and creates a dataframe of three indicators.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define countries, indicators form above, and time period\nwd.df <- WDI(country = \"all\", \n             indicator = c('population' = \"SP.POP.TOTL\", \n                           'gdp_pc' = \"NY.GDP.PCAP.KD\", \n                           'co2_pc' = \"EN.ATM.CO2E.PC\"),\n             extra = TRUE,\n             start = 2019, end = 2019)\n\n# Drop all country aggregrates\nwd.df <- wd.df[which(wd.df$region != \"Aggregates\"), ]\n\n# Save data\nsave(wd.df, file = \"WDI_short.RData\")\n```\n:::\n\n\n\n## Descriptive Inference\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\nlibrary(ggplot2)\npl <- ggplot(wd.df, aes(x = gdp_pc, y = co2_pc, size = population, color = region)) +\n  geom_point(alpha = 0.5) + \n  theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) +\n  labs(y = \"CO2 emissions per capita (log-transformed)\", x = \"GDP per capita (log-transformed)\")\n\npl\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/wdi_plot1-1.png){width=960}\n:::\n:::\n\n\n__Descriptive__: What are the average CO2 emissions of all European countries?\n\n## Descriptive Inference\n\nWhat are the average CO2 emissions of all European countries?\n\nMean by region\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nmean_co2 <- mean(wd.df$co2_pc[which(wd.df$region == \"Europe & Central Asia\")], \n                 na.rm = TRUE)\nmean_co2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.608387\n```\n:::\n:::\n\n\n. . .\n\nThis is the average across European countries.\n\n. . .\n\nWhy is it not the average across all Europeans?\n\n## Descriptive Inference {.smaller}\n\nWhat are the average CO2 emissions of all European countries?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Create group means (only for complete observations)\ntmp.df <- wd.df[, c(\"region\", \"gdp_pc\", \"co2_pc\")]\ntmp.df <- tmp.df[complete.cases(tmp.df),]\nmeans.df <- aggregate(tmp.df[, c(\"gdp_pc\", \"co2_pc\")],\n                      by = list(region = tmp.df$region),\n                      FUN = function(x) mean(x, na.rm = TRUE))\n\n# Plot\npl_mean <- ggplot(wd.df, aes(x = gdp_pc, y = co2_pc, color = region)) +\n  geom_point(data = wd.df, mapping = aes(x = gdp_pc, y = co2_pc, size = population, color = region),\n             alpha = 0.5) + \n  geom_point(data = means.df, \n                  mapping = aes(x = gdp_pc, y = co2_pc,  fill = region),\n                  size = 4, shape = 25, color = \"yellow\") +\n  theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) +\n  labs(y = \"CO2 emissions per capita (log-transformed)\", x = \"GDP per capita (log-transformed)\")\n\npl_mean\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/wdi_mean2-1.png){width=960}\n:::\n:::\n\n\n\n\n## Causal Inference\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\npl2 <- ggplot(wd.df, aes(x = gdp_pc, y = co2_pc, size = population, color = region)) +\n  geom_smooth(aes(group = 1), show.legend = \"none\") + geom_point(alpha = 0.5) + \n  theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) +\n  labs(y = \"CO2 emissions per capita (log-transformed)\", x = \"GDP per capita (log-transformed)\")\n\npl2\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/wdi_plot2-1.png){width=960}\n:::\n:::\n\n\n__Causal__: How does GDP influence the amount of CO2 emissions?\n\n\n## Variables and Observations  {.smaller}\n\nA [variable]{style=\"color: red;\"} is anything that can vary across units of analysis: it is a characteristic that can have multiple values\n\n* E.g., sex, age, diameter, financial revenue, temperature\n\n. . .\n\nA [unit of analysis]{style=\"color: blue;\"} is the major entity that you analyse\n\n*\tE.g., individuals, objects, schools, countries\n\n. . .\n\nAn [observation]{style=\"color: purple;\"} is the value of a particular variable for a particular unit (sometimes a unit is in its entirety referred to as observation)\n\n*\tE.g., the [individual]{style=\"color: blue;\"} King Charles III is [73 years]{style=\"color: purple;\"} of [age]{style=\"color: red;\"}\n\n\n## Different Types of Variables {.smaller}\n\n#### Continuous / interval-ratio variables: \n\nThey have an ordering, they can take on infinitely many values, and you can do calculations with them\n\n::: {.fragment .fade-in}\n* E.g., income, age, weight, minutes\n:::\n\n::: {.fragment .fade-in}\n#### Categorical variables: \n\nEach observation belongs to one out of a fixed number of categories \n\n* Ordinal variables: there is a natural ordering of the categories\n* Nominal variables: there is no natural ordering of the categories\n\n::: {.fragment .fade-in}\n  - E.g., education level, Likert scales, gender, vote choice\n:::\n:::\n\n# Describing variables\n\n## Decribing variables\n\nDescribing data is necessary because there is usually too much of it, so it does not make any sense to look at every data point\n\nWe thus have to look for ways to summarize central tendencies, variation, and relationships that exist in the data\n\nThere are many different ways to do this\n\n::: {.incremental}\n1) Visual depictions\n2) Numerical descriptions\n  - E.g. mean, mode, median, standard deviation\n:::\n\n\n## Distribution {.smaller}\n\nVariables can be characterized by their __frequency distribution__: \n\nThe distribution of the (relative) frequencies of their values  \n\n  - E.g., we can graph the world income distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\np <- ggplot(wd.df, aes(x = gdp_pc)) + geom_density() + \n  labs(y = \"Density\", x = \"GDP per capita\") + theme_bw()\np\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/distributions1-1.png){width=960}\n:::\n:::\n\n\n## Distributions: Examples\n\n::: {.incremental}\n* Normal distribution\n* Chi-squared distribution\n:::\n\n## Distributions: Example I\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\n# Seed for random number\nset.seed(12345)\n\n# Normal distribution\nd1 <- data.frame(x = rnorm(10000, 0, 1), dist = \"mean = 0, sd = 1\")\nd2 <- data.frame(x = rnorm(10000, 1, 1), dist = \"mean = 1, sd = 1\")\nd3 <- data.frame(x = rnorm(10000, 0, 2), dist = \"mean = 0, sd = 2\")\n\np <- ggplot(rbind(d1, d2, d3), aes(x = x)) + \n  geom_density(aes(color = dist, linetype = dist), size = 1.5) + \n  labs(y = \"Density\", x = \"Variable x\") + theme_bw() +\n  ggtitle(\"Normal distribution\")\np\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/distributions2-1.png){width=960}\n:::\n:::\n\n\n## Distributions: Example II\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\n# Chi Squared distribution\nd2 <- data.frame(x = rchisq(10000, 2), dist = \"df = 2\")\nd3 <- data.frame(x = rchisq(10000, 4), dist = \"df = 4\")\nd4 <- data.frame(x = rchisq(10000, 8), dist = \"df = 8\")\n\np <- ggplot(rbind(d2, d3, d4), aes(x = x)) + \n  geom_density(aes(color = dist, linetype = dist), size = 1.5) + \n  labs(y = \"Density\", x = \"Variable x\") + theme_bw() +\n  ggtitle(\"Chi-squared distribution\")\np\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/distributions3-1.png){width=960}\n:::\n:::\n\n\n## Distributions: Example III\n\n#### Distributions can take on many different shapes\n\n![](figs/Picture1.png)\n\n\n## Measures of Central Tendency {.smaller}\n\n__Mean__: conventional average calculated by adding all values for all units and dividing by the number of units\n\n$$\\overline{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}=\\frac{1}{n}\\left(x_{1}+\\cdots+x_{n}\\right), \\mathrm{with~units~}i = (1, 2, \\dots, n)$$\n\n* May give a distorted impression if there are outliers\n\n. . .\n\n__Median__: value that falls in the middle if we order all units by their value on the variable\n\n. . .\n\n__Mode__: most frequently occurring value across all units\n\n\n## Measures of Dispersion  {.smaller}\n\n__Variance__: average of the squared differences between each observed value on a variable and its mean \n$$\n\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2\n$$\n\n* Why the square? To treat + and – differences alike\n\n. . .\n\n__Standard deviation__: average departure of the observed values on a variable from its mean\n\n$$\n\\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2}\n$$\n\n* It is the square root of the variance; it “reverts” the square-taking in the variance calculation, to bring the statistic back to the original scale of the variable\n\n## Measures of Dispersion  {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"expand for full code\"}\n# Seed for random number\nset.seed(12345)\n\n# Normal distribution\nd1 <- data.frame(x = rnorm(10000, 0, 0.5), dist = \"sd = 0.5\")\nd2 <- data.frame(x = rnorm(10000, 0, 1), dist = \"sd = 1\")\nd3 <- data.frame(x = rnorm(10000, 0, 3), dist = \"sd = 3\")\n\np <- ggplot(rbind(d1, d2, d3), aes(x = x)) + \n  geom_density(aes(color = dist, linetype = dist), size = 1.5) + \n  labs(y = \"Density\", x = \"Variable x\") + theme_bw() +\n  ggtitle(\"Normal distribution\") + geom_vline(xintercept = 0)\np\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/distributions4-1.png){width=960}\n:::\n:::\n\n\n\n## Notation {.smaller}\n\nTypically, we use Roman letters for sample statistics and Greek letters for population statistics:\n\n* Sample mean $= \\bar{x}$ population mean $= \\mu$\n* Sample variance $= s^2$, population variance $= \\sigma^2$\n* Sample standard error $= s$, population standard deviation $= \\sigma$ \n\nRecall: the sample is what we observe, the population is what we want to make inferences about\n\n\n\n# Decribing relationships\n\n## Decribing relationships\n\nOften, we are not just interested in the distribution of a single variable. ^[Yeah, you could have spend the last 30 minutes on instagram!]\n\n. . .\n\nInstead, we are interested in __relationships__ between several variables. If there is a relationship between variable, knowing one variable can tell you something about the other variable.\n\n::: {.incremental}\n* Age and height\n* GDP and CO2 emissions\n* Education and income\n:::\n\n## Hypothesis testing \n\nA hypothesis is a theory-based statement about a relationship that we expect to observe\n\n* E.g., girls achieve higher scores than boys on reading tests \n\n. . .\n\nFor every hypothesis there is a corresponding null hypothesis about what we would expect if our theory is incorrect\n\n. . .\n\n* E.g., there is no association between Y and X in the population\n* In our example: girls are not better readers than boys \n\n\n## Covariance {.smaller}\n\n__Covariance__ refers to the idea that the pattern of variation for one variable corresponds to the pattern of variation for another variable: the two variables “vary together” \n\nStatistically speaking, covariance is the multiplication of the deviations from the mean for the first variables and the deviations from the mean for the second variable:\n\n$$cov_{x,y}=\\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})$$\n\n::: {.incremental}\n* The covariance tells us the direction of an association: + or – \n* It does not tell us about the strength of the association (reference to underlying distributions of variables is missing)\n:::\n\n\n\n## Pearson’s Correlation {.smaller}\n\nFor continuous data, we can calculate Pearson's correlation ($\\rho$)\n\n* $\\rho$ measures strength & direction of association for linear trends\n* $\\rho$ rescales the covariance to the underlying distributions of the variables involved:\n\n$$ \\rho = \\frac{cov_{x,y}}{\\sigma_X \\sigma_Y} = \n\\frac{\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}\n{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\bar{y})^2}}$$\n\n. . .\n\nDividing the covariance by the product of the standard deviations normalizes the covariance to a range from -1 to +1\n\n::: {.incremental}\n* -1 = perfectly negative correlation (all points on decreasing line)\n* +1 = perfectly positive correlation (all points on increasing line)\n* 0 = no correlation (random cloud of points)\n* Correlation is weaker closer to 0 and stronger closer to +/-1\n:::\n\n\n## Example I\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npl + ggtitle(paste(\"Pearsons correlation = \", \" ?\"))\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n\n## Example I\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# use log transformed variables\nwd.df$ln_gdp_pc <- log(wd.df$gdp_pc)\nwd.df$ln_co2_pc <- log(wd.df$co2_pc)\n\n# calculate covariance\ncov <- cov(wd.df$ln_gdp_pc, wd.df$ln_co2_pc, use = \"complete.obs\")\n\n# sd\nsd_gdp <- sd(wd.df$ln_gdp_pc, na.rm = TRUE)\nsd_co2 <- sd(wd.df$ln_co2_pc, na.rm = TRUE)\n\n# correlation\ncor <- cor(wd.df$ln_gdp_pc, wd.df$ln_co2_pc, use = \"complete.obs\")\n\n# Plot with linear line\npl3 <- ggplot(wd.df, aes(x = gdp_pc, y = co2_pc, size = population, color = region)) +\n  geom_smooth(aes(group = 1), method = 'lm', show.legend = \"none\") + \n  geom_point(alpha = 0.5) + \n  theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) +\n  labs(y = \"CO2 emissions per capita (log-transformed)\", x = \"GDP per capita (log-transformed)\") +\n  ggtitle(paste(\"Pearsons correlation = \", round(cor, 3)))\n\npl3\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n## Example II\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# use log transformed variables\nwd.df$ln_population <- log(wd.df$population)\nwd.df$ln_co2_pc <- log(wd.df$co2_pc)\n\n# calculate covariance\ncov <- cov(wd.df$ln_population, wd.df$ln_co2_pc, use = \"complete.obs\")\n\n# sd\nsd_gdp <- sd(wd.df$ln_population, na.rm = TRUE)\nsd_co2 <- sd(wd.df$ln_co2_pc, na.rm = TRUE)\n\n# correlation\ncor <- cor(wd.df$ln_population, wd.df$ln_co2_pc, use = \"complete.obs\")\n\n# Plot with linear line\npl3 <- ggplot(wd.df, aes(x = population, y = co2_pc, size = population, color = region)) +\n  # geom_smooth(aes(group = 1), method = 'lm', show.legend = \"none\") + \n  geom_point(alpha = 0.5) + \n  theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) +\n  labs(y = \"CO2 emissions per capita (log-transformed)\", x = \"Population\") +\n  ggtitle(paste(\"Pearsons correlation = \", \" ?\"))\n\npl3\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n## Example II\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Plot with linear line\npl3 <- pl3 +\n  geom_smooth(aes(group = 1), method = 'lm', show.legend = \"none\") + \n  ggtitle(paste(\"Pearsons correlation = \", round(cor, 3)))\n\npl3\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n## The world is more complex\n\n![](figs/R3.png)\n\n\n## The Linear Model {.smaller}\n\n$$\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\ldots +  \\beta_k x_{ki} +\\epsilon_i\n$$\n\n::: {.incremental}\n* $y_i$: $i$ observation $(i = 1, \\ldots , n)$ of dependent variable $y$ ;\n* $X_{ji}$: $i$ observation of $j$ explanatory variable $x$ $(j = 1, \\ldots, k)$.\n* $\\beta_j$: parameters to be estimated.\n* $\\epsilon_i$: error term. It contains all factors affecting $y_i$, but not contained in $x_{ji}$.\n:::\n\n## The OLS estimator {.smaller}\n\nThe Omitted Least Squares (OLS) estimator is one way to estimate the parameter $\\beta$ in our population model\n\nTo distinguish between estimates and actual parameters to be estimated, the following notation is generally used:\n\n* The estimate for $\\beta$ is indicated as $\\hat\\beta$\n* The estimated error term, also called residual is indicated as $\\hat\\epsilon$\n* The predicted value of the dependent variable $y$ is indicated as $\\hat y$\n\n## The OLS estimator {.smaller}\n\nThe OLS method chooses the estimates of $\\beta$ to minimise the sum of squared residuals (SSR)\n\n$$\n\\begin{align} \n\\min_{\\beta_0,\\dots x\\beta_k} [\\sum^N_{i=1}(Y_i-\\hat Y_i)^2] \\quad \\text{or}  \\quad\n\\min_{\\beta_0,\\dots x\\beta_k} [ \\hat{\\epsilon}^\\intercal \\hat{\\epsilon} ]\n\\end{align}\n$$\n\n\n. . .\n\nThe solution is the OLS estimator:\n$$\n\\begin{align} \n\\hat{\\beta}_{OLS} = \\frac{\\sum^N_{i = 1}(X_i - \\bar X)(Y_i - \\bar Y)}{\\sum^N_{i = 1}(X_i - \\bar X)^2}\n\\end{align}\n$$\n\nor in matrix notation:\n$$\n\\begin{align} \n\\hat{\\mathbf \\beta}_{OLS} = (\\mathbf X^\\intercal \\mathbf X)^{-1} \\mathbf X^\\intercal \\mathbf Y\n\\end{align}\n$$\n\n## An example: wage {.smaller}\n\n$$\nwage_i = \\beta_0 + \\beta_1 education_{i} + \\beta_2 union_{i} +\\epsilon_i\n$$\n\n::: {.incremental}\n* $y_i$: log-transformed wage of individual $i$;\n* $X_{1i}$: education years of individual $i$.\n* $X_{2i}$: whether or not individual $i$ is union member.\n* $\\epsilon_i$: error term. It contains all factors affecting the wage, but not contained in education years and union membership (such as age, gender, subject, quantitative methods skills, and lots more).\n:::\n\n## An example: wage {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Get example data \nlibrary(plm)\ndata(\"Wages\")\n\n# Reduce data frame to cross-section\nWages$year <- rep(c(1976:1982), 595)\nwages_cs.df <- Wages[which(Wages$year == 1976), ]\n\n# Reduce to 50 individual random sample\nset.seed(653210)\nwages_cs.df <- wages_cs.df[sample(1:595, 50), ]\n\n# Means\nmeans.df <- aggregate(wages_cs.df[, c(\"ed\", \"lwage\")],\n                      by = list(union = wages_cs.df$union),\n                      FUN = function(x) mean(x, na.rm = TRUE))\n\n# Plot with linear line\npl3 <- ggplot(wages_cs.df, aes(x = ed, y = lwage, color = union, shape = union)) +\n  geom_point(alpha = 1) + \n  geom_point(data = means.df, mapping = aes(color = union), \n             alpha = 0.5, stroke  = 2, size = 2, shape = c(1,2), show.legend = FALSE) +\n  theme_minimal() + \n  labs(y = \"log-transformed wage\", x = \"Education years\") +\n  ggtitle(\"50 individuals from the Panel Study of Income Dynamics\")\n\npl3\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/wages1-1.png){width=960}\n:::\n:::\n\n\n## An example: wage {.smaller}\n\nThe OLS estimator\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nmod1.lm <- lm(lwage ~ ed + union, data = wages_cs.df)\nsummary(mod1.lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = lwage ~ ed + union, data = wages_cs.df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.86123 -0.19264  0.01753  0.22068  0.59062 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  5.49218    0.25015  21.956  < 2e-16 ***\ned           0.06330    0.01746   3.626 0.000707 ***\nunionyes     0.16195    0.11259   1.438 0.156938    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3526 on 47 degrees of freedom\nMultiple R-squared:  0.2186,\tAdjusted R-squared:  0.1853 \nF-statistic: 6.574 on 2 and 47 DF,  p-value: 0.003039\n```\n:::\n:::\n\n\n<!-- ## An example: wage {.smaller} -->\n\n\n<!-- ```{r wages3} -->\n<!-- #| echo: true -->\n<!-- #| code-fold: true -->\n<!-- # Plot with linear line -->\n<!-- pl3 <- ggplot(wages_cs.df, aes(x = ed, y = lwage, color = union, shape = union)) + -->\n<!--   geom_point(alpha = 1) +  -->\n<!--   theme_minimal() +  -->\n<!--   labs(y = \"log-transformed wage\", x = \"Education years\") + -->\n<!--   ggtitle(\"50 individuals from the Panel Study of Income Dynamics\") -->\n\n<!-- pl3 -->\n<!-- ``` -->\n\n## An example: wage {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(gganimate)\n\n# Residualise y\ntmp.mod1 <- lm(lwage ~ union, data = wages_cs.df)\nwages_cs.df$lwage_resid <- resid(tmp.mod1)\n\n# Residualise x\ntmp.mod1 <- lm(ed ~ union, data = wages_cs.df)\nwages_cs.df$ed_resid <- resid(tmp.mod1)\n\n# Create data of states to animate\ndf <- rbind(data.frame(lwage = wages_cs.df$lwage,\n                       ed = wages_cs.df$ed,\n                       union = wages_cs.df$union,\n                       resid = 0),\n            data.frame(lwage = wages_cs.df$lwage_resid,\n                       ed = wages_cs.df$ed,\n                       union = wages_cs.df$union,\n                       resid = 1),\n            data.frame(lwage = wages_cs.df$lwage_resid, # just to duplicate\n                       ed = wages_cs.df$ed,\n                       union = wages_cs.df$union,\n                       resid = 2),\n            data.frame(lwage = wages_cs.df$lwage_resid,\n                       ed = wages_cs.df$ed_resid,\n                       union = wages_cs.df$union,\n                       resid = 3),\n            data.frame(lwage = wages_cs.df$lwage_resid, # just to duplicate\n                       ed = wages_cs.df$ed_resid,\n                       union = wages_cs.df$union,\n                       resid = 4),\n            data.frame(lwage = wages_cs.df$lwage_resid, # just to duplicate\n                       ed = wages_cs.df$ed_resid,\n                       union = wages_cs.df$union,\n                       resid = 5))\n\nmeans.df <- aggregate(df[, c(\"lwage\", \"ed\")],\n                   by = list(union = df$union,\n                             resid = df$resid),\n                  FUN = function(x) mean(x, na.rm = TRUE))\n\n\n# Plot with linear line\npl4 <- ggplot(df, aes(x = ed, y = lwage, color = union, shape = union)) +\n  geom_point(alpha = 1) + \n  geom_point(data = means.df, \n             alpha = 0.5, stroke  = 2, size = 2, show.legend = FALSE) +\n  theme_minimal() + \n  labs(y = \"log-transformed wage\", x = \"Education years\") +\n  ggtitle(\"50 individuals from the Panel Study of Income Dynamics\")+\n  transition_states(resid, wrap = FALSE) + \n  shadow_mark(alpha = 0.7, size = 1) \n  # + view_zoom(nsteps = 3, include = TRUE, \n  #           look_ahead = 4, wrap = FALSE)\n\npl4\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/wages4-1.gif)\n:::\n:::\n\n\n\n\n## An example: wage {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Means\nmeans.df <- aggregate(wages_cs.df[, c(\"ed_resid\", \"lwage_resid\")],\n                      by = list(union = wages_cs.df$union),\n                      FUN = function(x) mean(x, na.rm = TRUE))\n\n# Plot with linear line\npl5_0 <- ggplot(wages_cs.df, aes(x = ed_resid, y = lwage_resid)) +\n  geom_point(aes(color = union, shape = union), alpha = 1) + \n  geom_point(data = means.df, mapping = aes(color = union), \n             alpha = 0.5, stroke  = 2, size = 2, shape = c(1,2), show.legend = FALSE) +\n  theme_minimal() + \n  labs(y = \"residualized log-transformed wage\", x = \"residualized Education years\") +\n  ggtitle(\"50 individuals from the Panel Study of Income Dynamics\")\n\npl5_0\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/wages5_0-1.png){width=960}\n:::\n:::\n\n\n\n## An example: wage {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n # fit the model\nfit <- lm(lwage_resid ~ ed_resid, data = wages_cs.df)\n\n# Save the predicted values\nwages_cs.df$predicted <- predict(fit)\n\n# Save the residual values\nwages_cs.df$residuals <- residuals(fit)\n\nlibrary(ggpubr)\n\n# Plot with linear line\npl5 <- ggplot(wages_cs.df, aes(x = ed_resid, y = lwage_resid)) +\n  geom_point(aes(color = union, shape = union), alpha = 1) + \n  geom_point(data = means.df, mapping = aes(color = union), \n             alpha = 0.5, stroke  = 2, size = 2, shape = c(1,2), show.legend = FALSE) +\n  geom_smooth(aes(group = 1), method = 'lm', show.legend = \"none\", se = FALSE) +\n  geom_segment(aes(xend = ed_resid, yend = predicted), alpha = .2, color = \"purple\") +\n  geom_point(aes(x = ed_resid, y = predicted), alpha = 0.5, shape = 1, color = \"red\") + \n  theme_minimal() + \n  labs(y = \"residualized log-transformed wage\", x = \"residualized Education years\") +\n  ggtitle(\"50 individuals from the Panel Study of Income Dynamics\") +\n  stat_regline_equation(aes(label = ..eq.label..))\n\npl5\n```\n\n::: {.cell-output-display}\n![](Bootcamp_slides_files/figure-revealjs/wages5-1.png){width=960}\n:::\n:::\n\n\n\n\n\n<!-- ## An example: wage {.smaller} -->\n\n<!-- ```{r wages5} -->\n<!-- #| echo: true -->\n<!-- #| code-fold: true -->\n\n<!-- # Residualise x -->\n<!-- tmp.mod1 <- lm(ed ~ union, data = wages_cs.df) -->\n<!-- wages_cs.df$ed_resid <- resid(tmp.mod1) -->\n\n<!-- # Plot with linear line -->\n<!-- pl5 <- ggplot(wages_cs.df, aes(x = ed_resid, y = lwage_resid)) + -->\n<!--   geom_point(alpha = 0.5) +  -->\n<!--   theme_minimal() +  -->\n<!--   labs(y = \"log-transformed wage\", x = \"residualized Education years\") + -->\n<!--   ggtitle(\"50 individuals from the Panel Study of Income Dynamics\") -->\n\n<!-- pl5 -->\n<!-- ``` -->\n\n<!-- ## The OLS estimator {.smaller} -->\n\n<!-- ```{r} -->\n<!--  # fit the model -->\n<!-- fit <- lm(co2_pc ~ gdp_pc, data = wd.df) -->\n\n<!-- # Save the predicted values -->\n<!-- wd.df$predicted <- NA -->\n<!-- wd.df$predicted[-fit$na.action] <- predict(fit)   -->\n\n<!-- # Save the residual values -->\n<!-- wd.df$residuals <- NA -->\n<!-- wd.df$residuals[-fit$na.action] <- residuals(fit)  -->\n\n<!-- # Plot -->\n<!-- # Plot with linear line -->\n<!-- pl4 <- ggplot(wd.df, aes(x = gdp_pc, y = co2_pc)) + -->\n<!--   geom_smooth(aes(group = 1), method = 'lm', show.legend = \"none\", se = FALSE) +  -->\n<!--   geom_segment(aes(xend = gdp_pc, yend = predicted), alpha = .2) + -->\n<!--   geom_point(aes(color = abs(residuals), size = abs(residuals)), alpha = 0.5) +  -->\n<!--   scale_color_continuous(low = \"green\", high = \"red\") + -->\n<!--   theme_minimal() + scale_y_log10() +  scale_x_log10(labels = scales::dollar_format()) + -->\n<!--   labs(y = \"CO2 emissions per capita (log-transformed)\", x = \"GDP per capita (log-transformed)\") + -->\n<!--   ggtitle(paste(\"Pearsons correlation = \", round(cor, 3))) -->\n\n<!-- pl4 -->\n<!-- ``` -->\n\n\n# Statistical Software\n\n## UCL Download centre\n\n[https://www.ucl.ac.uk/isd/services/software-hardware/software-for-students](https://www.ucl.ac.uk/isd/services/software-hardware/software-for-students)\n\n## Statistical software\n\n__Stata__ & __R__ are powerful software packages that allows you to do: \n\n* Data management and manipulation\n* Data visualization \n* Statistical analysis\n\n. . .\n\n* (Writing papers and presentations)\n\n. . .\n\nWriting Stata syntax files and R script facilitates __reproducibility__\n\n\n## Stata’s Interface: Variables Window {.smaller}\n\nThe variables window displays all variables in your dataset \n\n![](figs/Stata1.png)\n\n* Single click on variable names to see details in properties window\n* Double click to make variables appear in command window\n\n\n## Stata’s Interface: Properties Window {.smaller}\n\nThe variables window displays all variables in your dataset \n\n![](figs/Stata2.png)\n\nThe properties window displays details about selected variables as well as the entire dataset (e.g., number of observations, sort order)\n\n\n## Stata’s Interface: Command Window {.smaller}\n\n![](figs/Stata3.png)\n\nThe command window is for entering and executing commands\n\n* But it is better to use do-files (same applies to drop-down menus)\n\n\n## Stata’s Interface: Results Window  {.smaller}\n\n![](figs/Stata4.png)\n\nThe results window displays all output of your commands\n\n\n## Stata’s Interface: Command History and Current Working Directory {.smaller}\n\n![](figs/Stata5.png)\n\nThe command history window lists previously run commands \n\n* At the bottom you can see the current working directory: the folder where any files will be loaded from and saved to\n\n\n## Stata’s Interface: Opening a Do File {.smaller}\n\n![](figs/Stata6.png)\n\nDo files are text files where you can store commands for reuse\n\n* Huge payoffs for reproducibility, debugging, adapting commands\n\n\n## Running Commands from a Do File {.smaller}\n\n![](figs/Stata7.png)\n\nAfter entering a command, you select it, and then click the “execute” button or press “Ctrl+D”\n\n\n## Do File Dos and Don’ts {.smaller}\n\n![](figs/Stata8.png)\n\n1. Use annotations to facilitate replicability (incl. for future self!):\n\t* Use * for single-line comments and /* */ for multiple lines \n\n## Do File Dos and Don’ts {.smaller}\n\t\n![](figs/Stata9.png)\t\n\n2. Break down code into clearly labelled sections / subsections\n3. Use tab indentations to making things easy to read\n\n## Do File Dos and Don’ts {.smaller}\n\n![](figs/Stata10.png)\t\n\n4. Don’t put too much information on a single line\n\n* Use /// to continue your command on the next line and \n* write “top-to-bottom” instead of “left-to-right” \n\n\n## R & R Studio Interface\n\n![](figs/R1.png)\t\n\n\n# Structure of Commands in Stata\n\n## General Stata Command Syntax\n\n![](figs/Stata11.png)\n\nStata commands mirror everyday commands in their structure:\n\n::: {.incremental}\n* They often start with a verb: “Bring me…” \n* They then list an object: “… a pint of milk…”\n* They may add a condition: “… if it is still before noon…” \n* They may specify further details after the comma: “, quickly please” or “, I want semi-skimmed”\n:::\n\n## {auto-animate=true}\n\n![](figs/Stata11.png)\n\nIn nearly all cases, Stata syntax consists of four parts: \n\n::: {.incremental}\n* __Command__: What action do you want to see performed? \n* __Names of variables__, files, objects: On what objects is the command to be performed (“varlist”)\n* __Qualifier(s) on observations__: Which observations are to be taken into account (and how)? (“if”, “in”, “weight”)\n* __Options__: What special things should be done in the execution?\n:::\n\n\n## \"help [command]\" is your friend\n\n![](figs/Stata12.png)\n\n```{.stata}\nhelp summarize\n```\n\n\n# Structure of Commands in R\n\n\n## General R Workflow\n\n\n```{.r code-line-numbers=\"1\"}\nobject_name <- value\n\n# Example\na <- 3\nb <- 4\nc <- a + b\nc\n```\n\n* Assign a value to an object\n\n## General R Workflow\n\n```{.r code-line-numbers=\"4,5\"}\nobject_name <- value\n\n# Example\na <- 3\nb <- 4\nc <- a + b\nc\n```\n\n* Define the objects a and b\n\n## General R Workflow\n\n```{.r code-line-numbers=\"6\"}\nobject_name <- value\n\n# Example\na <- 3\nb <- 4\nc <- a + b\nc\n```\n\n* Perform an operations with them\n\n\n::: {.cell}\n\n:::\n\n\n\n## General R Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"7\"}\nobject_name <- value\n\n# Example\na <- 3\nb <- 4\nc <- a + b\nc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7\n```\n:::\n:::\n\n\n* Return the results\n\n\n## General R Syntax\n\n```{.r}\nfunction_name(arg1 = val1[which()], arg2 = val2[which()], option1 = val3, ...)\n```\n\n::: {.incremental}\n* __function_name__: What action do you want to see performed? \n* __args__, files, objects: On what objects is the command to be performed \n* __Qualifier(s) on observations__: Which observations are to be taken into account (and how)? (“which”)\n* __options__: What special things should be done in the execution?\n:::\n\n\n## General R Syntax\n\nProduce a sequence between 0 and 10 with 20 values\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- seq(0, 10, length.out = 20)\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  0.0000000  0.5263158  1.0526316  1.5789474  2.1052632  2.6315789\n [7]  3.1578947  3.6842105  4.2105263  4.7368421  5.2631579  5.7894737\n[13]  6.3157895  6.8421053  7.3684211  7.8947368  8.4210526  8.9473684\n[19]  9.4736842 10.0000000\n```\n:::\n:::\n\n\nCalculate the mean\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\nCalculate the mean of all values above 5\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(y[which(y >= 5)])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7.631579\n```\n:::\n:::\n\n\n\n\n## \"?[command]\" is your friend\n\n![](figs/R2.png)\n\n```{.r}\n?seq\n```\n\n\n## Define your working directory {.smaller}\n\nThis is a path: \"C:/work/Lehre/Bootcamp_slides/\" (look the slash direction)\n\n![](figs/file.png)\n\n\n## Define your working directory\n\n#### Stata\n\n```{.stata}\ncd \"C:/work/Lehre/Bootcamp_slides/\"\n```\n\n\n#### R\n\n```{.r}\nsetwd('C:/work/Lehre/Bootcamp_slides/')\n```\n\n\n\n## There are a lot of helpful resources\n\n* [Stata Cheatsheet](https://www.stata.com/bookstore/statacheatsheets.pdf)\n\n* [Base R Cheatsheet](https://iqss.github.io/dss-workshops/R/Rintro/base-r-cheat-sheet.pdf)\n\n* [Tidy R Cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)\n\n\n",
    "supporting": [
      "Bootcamp_slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}